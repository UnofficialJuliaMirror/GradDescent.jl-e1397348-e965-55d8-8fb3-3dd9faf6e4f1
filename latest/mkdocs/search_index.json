{
    "docs": [
        {
            "location": "/", 
            "text": "GradDescent\n\n\n#\n\n\nGradDescent\n \n \nModule\n.\n\n\nGradient Descent optimizers for Julia.\n\n\nIntroduction\n\n\nThis package abstracts the \"boilerplate\" code necessary for gradient descent. Gradient descent is \"a way to minimize an objective function $J(\u03b8)$ parameterized by a model's parameters $\u03b8 \u2208 R\u1d48$\" (Ruder 2017). Gradient descent finds $\u03b8$ which minizes $J$ by iterating over the following update\n\n\n$\u03b8 = \u03b8 - \u03b7 \u2207J(\u03b8)$\n\n\nuntil convergence of $\u03b8$. Certainly, the gradient calculation is model specific, however the learning rate $\u03b7$ (at a given iteration) is not. Instead there are many different gradient descent variants which determine the learning rate. Each type of gradient descent optimizer has its own pros/cons. For most of these optimizers, the calculation of the learning rate is based on the value of the gradient (evaluated at a particular $\u03b8$) and a few (unrelated to the model) hyperparameters. \n\n\nThe purpose of this package is to allow the user to focus on the calculation of the gradients and not worry about the code for the gradient descent optimizer. I envision a user implementing his/her gradients, experimenting with various optimizers, and modifying the gradients as necessary.\n\n\nExamples\n\n\nHere I demonstrate a very simple example - minimizing $x\u00b2$. In this example, I use \"Adagrad\", a common gradient descent optimizer.\n\n\nusing GradDescent\n\n# objective function and gradient of objective function\nJ(x) = x ^ 2\ndJ(x) = 2 * x\n\n# number of epochs\nepochs = 1000\n\n# instantiation of Adagrad optimizer with default hyperparameters\nopt = Adagrad()\n\n# initial value for x (usually initialized with a random value)\nx = 4.0\n\nfor i in 1:epochs\n    # calculate the gradient wrt to the current x\n    g = dJ(x)\n\n    # change to the current x\n    \u03b4 = update(opt, g)\n    x -= \u03b4\nend\n\n# inspect minimized form, should be close to 0.0\nprintln(x)\n\n\n\n\nsource\n\n\n\n\nIndex", 
            "title": "Home"
        }, 
        {
            "location": "/#graddescent", 
            "text": "#  GradDescent     Module .  Gradient Descent optimizers for Julia.  Introduction  This package abstracts the \"boilerplate\" code necessary for gradient descent. Gradient descent is \"a way to minimize an objective function $J(\u03b8)$ parameterized by a model's parameters $\u03b8 \u2208 R\u1d48$\" (Ruder 2017). Gradient descent finds $\u03b8$ which minizes $J$ by iterating over the following update  $\u03b8 = \u03b8 - \u03b7 \u2207J(\u03b8)$  until convergence of $\u03b8$. Certainly, the gradient calculation is model specific, however the learning rate $\u03b7$ (at a given iteration) is not. Instead there are many different gradient descent variants which determine the learning rate. Each type of gradient descent optimizer has its own pros/cons. For most of these optimizers, the calculation of the learning rate is based on the value of the gradient (evaluated at a particular $\u03b8$) and a few (unrelated to the model) hyperparameters.   The purpose of this package is to allow the user to focus on the calculation of the gradients and not worry about the code for the gradient descent optimizer. I envision a user implementing his/her gradients, experimenting with various optimizers, and modifying the gradients as necessary.  Examples  Here I demonstrate a very simple example - minimizing $x\u00b2$. In this example, I use \"Adagrad\", a common gradient descent optimizer.  using GradDescent\n\n# objective function and gradient of objective function\nJ(x) = x ^ 2\ndJ(x) = 2 * x\n\n# number of epochs\nepochs = 1000\n\n# instantiation of Adagrad optimizer with default hyperparameters\nopt = Adagrad()\n\n# initial value for x (usually initialized with a random value)\nx = 4.0\n\nfor i in 1:epochs\n    # calculate the gradient wrt to the current x\n    g = dJ(x)\n\n    # change to the current x\n    \u03b4 = update(opt, g)\n    x -= \u03b4\nend\n\n# inspect minimized form, should be close to 0.0\nprintln(x)  source", 
            "title": "GradDescent"
        }, 
        {
            "location": "/#index", 
            "text": "", 
            "title": "Index"
        }
    ]
}